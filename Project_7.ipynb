{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from functools import partial\n",
        "import random\n",
        "import keras\n",
        "from keras.datasets import mnist"
      ],
      "metadata": {
        "id": "ZzrJPFN2NivG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridMPSOCNN:\n",
        "    def __init__(self, input_shape, max_iters_level1, max_iters_level2, alpha, tmax, num_classes):\n",
        "        self.input_shape = input_shape\n",
        "        self.max_iters_level1 = max_iters_level1\n",
        "        self.max_iters_level2 = max_iters_level2\n",
        "        self.alpha = alpha\n",
        "        self.tmax = tmax\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def cnn(self, Pi, Pij, X_train, y_train, X_val, y_val):\n",
        "      model = Sequential()\n",
        "      # Pi = (nC, nP, nF)\n",
        "      nC, nP, nF = [int(x) for x in Pi]\n",
        "      # Pij = (c_nf, c_fs, c_pp, c_ss, p_fs, p_ss, p_pp, op)\n",
        "      for i in range(nC):\n",
        "          c_nf, c_fs, c_pp, c_ss = [int(x) for x in Pij[:4]]\n",
        "          padding = 'same'\n",
        "          if i == 0:\n",
        "              model.add(Conv2D(c_nf, (c_fs, c_fs), strides=(c_ss, c_ss), padding=padding, activation='relu', input_shape=self.input_shape))\n",
        "          else:\n",
        "              model.add(Conv2D(c_nf, (c_fs, c_fs), strides=(c_ss, c_ss), padding=padding, activation='relu'))\n",
        "          padding = 'same'\n",
        "          if i < nP:\n",
        "              p_fs, p_ss, p_pp = [int(x) for x in Pij[4:7]]\n",
        "              p_fs = max(p_fs, 2)\n",
        "              p_ss = max(p_ss, 2)\n",
        "              if X_train.shape[1] >= p_fs and X_train.shape[2] >= p_fs:\n",
        "                  model.add(MaxPooling2D(pool_size=(p_fs, p_fs), strides=(p_ss, p_ss), padding=padding))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      for i in range(nF):\n",
        "          model.add(Dense(int(Pij[7]), activation='relu'))\n",
        "      model.add(Dense(self.num_classes, activation='softmax'))\n",
        "      model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "      history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=1, verbose=1)\n",
        "      loss, accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
        "      val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "      print(\"Train loss: {:.4f}, accuracy: {:.4f}\".format(loss, accuracy))\n",
        "      print(\"Validation loss: {:.4f}, accuracy: {:.4f}\".format(val_loss, val_accuracy))\n",
        "      fitness = np.max(history.history['val_accuracy'])\n",
        "      return fitness\n",
        "\n",
        "\n",
        "    def level2_pso(self, Pi, X_train, y_train, X_val, y_val, search_space):\n",
        "        m2 = 5 * (Pi[0] + Pi[1])\n",
        "        tmax2 = self.max_iters_level2\n",
        "        n_particles = m2\n",
        "\n",
        "        # Ensure pool size does not exceed input dimensions\n",
        "        search_space[4, 1] = min(self.input_shape[0], search_space[4, 1])\n",
        "        search_space[4, 1] = min(self.input_shape[1], search_space[4, 1])\n",
        "\n",
        "        particles = np.random.uniform(search_space[:, 0], search_space[:, 1], (n_particles, search_space.shape[0])).astype(int)\n",
        "        pbest = particles.copy()\n",
        "        gbest = particles[np.argmax([self.cnn(Pi, p, X_train, y_train, X_val, y_val) for p in particles])]\n",
        "        vel = np.zeros_like(particles)\n",
        "\n",
        "        for t in range(tmax2):\n",
        "            for i, particle in enumerate(particles):\n",
        "                vel = vel.astype('float64')\n",
        "                particle = particle.astype('float64')\n",
        "                vel[i] += 2 * np.random.rand() * (pbest[i] - particle) + 2 * np.random.rand() * (gbest - particle)\n",
        "                vel = np.clip(vel, search_space[:, 0] - particle, search_space[:, 1] - particle)\n",
        "                particle += vel[i].astype(int)\n",
        "\n",
        "\n",
        "                new_fitness = self.cnn(Pi, particle, X_train, y_train, X_val, y_val)\n",
        "                if new_fitness > self.cnn(Pi, pbest[i], X_train, y_train, X_val, y_val):\n",
        "                    pbest[i] = particle.copy()\n",
        "                if new_fitness > self.cnn(Pi, gbest, X_train, y_train, X_val, y_val):\n",
        "                    gbest = particle.copy()\n",
        "\n",
        "        return gbest\n",
        "\n",
        "    def level1_pso(self, X_train, y_train, X_val, y_val):\n",
        "        m1 = 5\n",
        "        search_space_1 = np.array([(1, 5), (1, 5), (1, 5)], dtype=np.int32)\n",
        "        search_space_2 = np.array([(1, 64), (1, 7), (0, 1), (1, 3), (1, 7), (1, 3), (0, 1), (1, 1024)], dtype=np.int32)\n",
        "\n",
        "        c1 = 2\n",
        "        c2 = 2\n",
        "        n_particles = m1\n",
        "        tmax1 = self.max_iters_level1\n",
        "\n",
        "        particles = np.random.uniform(search_space_1[:, 0], search_space_1[:, 1], (n_particles, search_space_1.shape[0])).astype(int)\n",
        "        pbest = particles.copy()\n",
        "        gbest = particles[np.argmax([self.level2_pso(p, X_train, y_train, X_val, y_val, search_space_2) for p in particles])]\n",
        "        vel = np.zeros_like(particles)\n",
        "\n",
        "        for t in range(tmax1):\n",
        "            if t < self.alpha * self.tmax:\n",
        "                w = 0.9\n",
        "            else:\n",
        "                w = 1 / (1 + np.exp(10 * t - 2 * tmax1) / tmax1)\n",
        "\n",
        "            for i, particle in enumerate(particles):\n",
        "                vel[i] += c1 * np.random.rand() * (pbest[i] - particle) + c2 * np.random.rand() * (gbest - particle)\n",
        "                vel = np.clip(vel, search_space_1[:, 0] - particle, search_space_1[:, 1] - particle)\n",
        "                particle += vel[i].astype(int)\n",
        "\n",
        "                new_fitness = self.level2_pso(particle, X_train, y_train, X_val, y_val, search_space_2)\n",
        "                if new_fitness > self.level2_pso(pbest[i], X_train, y_train, X_val, y_val, search_space_2):\n",
        "                    pbest[i] = particle.copy()\n",
        "                if new_fitness > self.level2_pso(gbest, X_train, y_train, X_val, y_val, search_space_2):\n",
        "                    gbest = particle.copy()\n",
        "\n",
        "        gbest_particle = self.level2_pso(gbest, X_train, y_train, X_val, y_val, search_space_2)\n",
        "        return gbest, gbest_particle\n",
        "\n",
        "    def run(self, X_train, y_train, X_val, y_val):\n",
        "        level1_opt, level2_opt = self.level1_pso(X_train, y_train, X_val, y_val)\n",
        "        print(\"Optimal level 1 parameters:\", level1_opt)  # [nC, nP, nF]\n",
        "        print(\"Optimal level 2 parameters:\", level2_opt)  # [c_nf, c_cs, c_pp, c_ss, p_fs, p_ss, p_pp, op]"
      ],
      "metadata": {
        "id": "vKPnjHqcNhNB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data: normalize and reshape the images\n",
        "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "\n",
        "# Convert the labels to one-hot encoded format\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Create an instance of HybridMPSOCNN optimizer\n",
        "input_shape = (28, 28, 1)\n",
        "max_iters_level1 = 10\n",
        "max_iters_level2 = 10\n",
        "alpha = 0.2\n",
        "tmax = 10\n",
        "num_classes = 10\n",
        "\n",
        "optimizer = HybridMPSOCNN(input_shape, max_iters_level1, max_iters_level2, alpha, tmax, num_classes)\n",
        "\n",
        "# Run optimization\n",
        "X_val, y_val = X_test, y_test\n",
        "optimizer.run(X_train, y_train, X_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ds6zuqBMNopm",
        "outputId": "d1b29add-939c-473a-cb9e-bd2a2cc5ef73"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "1875/1875 [==============================] - 23s 6ms/step - loss: 0.3396 - accuracy: 0.8913 - val_loss: 0.1684 - val_accuracy: 0.9514\n",
            "Train loss: 0.1608, accuracy: 0.9522\n",
            "Validation loss: 0.1684, accuracy: 0.9514\n",
            "1875/1875 [==============================] - 16s 6ms/step - loss: 0.3671 - accuracy: 0.8830 - val_loss: 0.2875 - val_accuracy: 0.9078\n",
            "Train loss: 0.2733, accuracy: 0.9112\n",
            "Validation loss: 0.2875, accuracy: 0.9078\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 2.2737 - accuracy: 0.1306 - val_loss: 2.2693 - val_accuracy: 0.1328\n",
            "Train loss: 2.2692, accuracy: 0.1332\n",
            "Validation loss: 2.2693, accuracy: 0.1328\n",
            "1875/1875 [==============================] - 16s 6ms/step - loss: 0.3688 - accuracy: 0.8709 - val_loss: 0.0737 - val_accuracy: 0.9763\n",
            "Train loss: 0.0778, accuracy: 0.9758\n",
            "Validation loss: 0.0737, accuracy: 0.9763\n",
            "1875/1875 [==============================] - 16s 6ms/step - loss: 0.1555 - accuracy: 0.9563 - val_loss: 0.1004 - val_accuracy: 0.9775\n",
            "Train loss: 0.0917, accuracy: 0.9786\n",
            "Validation loss: 0.1004, accuracy: 0.9775\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.4237 - accuracy: 0.8571 - val_loss: 0.1529 - val_accuracy: 0.9530\n",
            "Train loss: 0.1560, accuracy: 0.9525\n",
            "Validation loss: 0.1529, accuracy: 0.9530\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.7088 - accuracy: 0.7427 - val_loss: 0.2861 - val_accuracy: 0.9121\n",
            "Train loss: 0.3066, accuracy: 0.9043\n",
            "Validation loss: 0.2861, accuracy: 0.9121\n",
            "1875/1875 [==============================] - 16s 7ms/step - loss: 0.1936 - accuracy: 0.9406 - val_loss: 0.0546 - val_accuracy: 0.9843\n",
            "Train loss: 0.0610, accuracy: 0.9835\n",
            "Validation loss: 0.0546, accuracy: 0.9843\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.3497 - accuracy: 0.8749 - val_loss: 0.1328 - val_accuracy: 0.9626\n",
            "Train loss: 0.1274, accuracy: 0.9632\n",
            "Validation loss: 0.1328, accuracy: 0.9626\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.2847 - accuracy: 0.9071 - val_loss: 0.0983 - val_accuracy: 0.9710\n",
            "Train loss: 0.1033, accuracy: 0.9701\n",
            "Validation loss: 0.0983, accuracy: 0.9710\n",
            "1875/1875 [==============================] - 16s 6ms/step - loss: 0.1459 - accuracy: 0.9555 - val_loss: 0.0738 - val_accuracy: 0.9788\n",
            "Train loss: 0.0654, accuracy: 0.9815\n",
            "Validation loss: 0.0738, accuracy: 0.9788\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1611 - accuracy: 0.9535 - val_loss: 0.0611 - val_accuracy: 0.9833\n",
            "Train loss: 0.0548, accuracy: 0.9849\n",
            "Validation loss: 0.0611, accuracy: 0.9833\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 2.2766 - accuracy: 0.1298 - val_loss: 2.2726 - val_accuracy: 0.1312\n",
            "Train loss: 2.2733, accuracy: 0.1318\n",
            "Validation loss: 2.2726, accuracy: 0.1312\n",
            "1875/1875 [==============================] - 16s 7ms/step - loss: 0.1528 - accuracy: 0.9563 - val_loss: 0.0668 - val_accuracy: 0.9834\n",
            "Train loss: 0.0631, accuracy: 0.9851\n",
            "Validation loss: 0.0668, accuracy: 0.9834\n",
            "1875/1875 [==============================] - 16s 7ms/step - loss: 0.3002 - accuracy: 0.8989 - val_loss: 0.0818 - val_accuracy: 0.9795\n",
            "Train loss: 0.0813, accuracy: 0.9796\n",
            "Validation loss: 0.0818, accuracy: 0.9795\n",
            "1875/1875 [==============================] - 16s 7ms/step - loss: 0.3206 - accuracy: 0.9006 - val_loss: 0.2458 - val_accuracy: 0.9290\n",
            "Train loss: 0.2350, accuracy: 0.9338\n",
            "Validation loss: 0.2458, accuracy: 0.9290\n",
            "1875/1875 [==============================] - 17s 7ms/step - loss: 0.4330 - accuracy: 0.8502 - val_loss: 0.1291 - val_accuracy: 0.9643\n",
            "Train loss: 0.1375, accuracy: 0.9628\n",
            "Validation loss: 0.1291, accuracy: 0.9643\n",
            "1875/1875 [==============================] - 20s 8ms/step - loss: 0.1566 - accuracy: 0.9561 - val_loss: 0.0681 - val_accuracy: 0.9808\n",
            "Train loss: 0.0630, accuracy: 0.9824\n",
            "Validation loss: 0.0681, accuracy: 0.9808\n",
            "1875/1875 [==============================] - 16s 7ms/step - loss: 0.1494 - accuracy: 0.9550 - val_loss: 0.0670 - val_accuracy: 0.9812\n",
            "Train loss: 0.0600, accuracy: 0.9835\n",
            "Validation loss: 0.0670, accuracy: 0.9812\n",
            "1875/1875 [==============================] - 16s 7ms/step - loss: 0.3776 - accuracy: 0.8698 - val_loss: 0.1273 - val_accuracy: 0.9646\n",
            "Train loss: 0.1270, accuracy: 0.9635\n",
            "Validation loss: 0.1273, accuracy: 0.9646\n",
            "1875/1875 [==============================] - 16s 7ms/step - loss: 0.1447 - accuracy: 0.9571 - val_loss: 0.0640 - val_accuracy: 0.9828\n",
            "Train loss: 0.0642, accuracy: 0.9832\n",
            "Validation loss: 0.0640, accuracy: 0.9828\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.3605 - accuracy: 0.8736 - val_loss: 0.1344 - val_accuracy: 0.9611\n",
            "Train loss: 0.1507, accuracy: 0.9569\n",
            "Validation loss: 0.1344, accuracy: 0.9611\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1500 - accuracy: 0.9535 - val_loss: 0.0461 - val_accuracy: 0.9855\n",
            "Train loss: 0.0470, accuracy: 0.9855\n",
            "Validation loss: 0.0461, accuracy: 0.9855\n",
            "1875/1875 [==============================] - 18s 7ms/step - loss: 0.6178 - accuracy: 0.8047 - val_loss: 0.1812 - val_accuracy: 0.9623\n",
            "Train loss: 0.1730, accuracy: 0.9639\n",
            "Validation loss: 0.1812, accuracy: 0.9623\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 2.3017 - accuracy: 0.1111 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Train loss: 2.3012, accuracy: 0.1124\n",
            "Validation loss: 2.3011, accuracy: 0.1135\n",
            "1875/1875 [==============================] - 16s 6ms/step - loss: 0.1584 - accuracy: 0.9506 - val_loss: 0.0497 - val_accuracy: 0.9842\n",
            "Train loss: 0.0516, accuracy: 0.9846\n",
            "Validation loss: 0.0497, accuracy: 0.9842\n",
            "1875/1875 [==============================] - 14s 6ms/step - loss: 0.3466 - accuracy: 0.8875 - val_loss: 0.2041 - val_accuracy: 0.9365\n",
            "Train loss: 0.1998, accuracy: 0.9396\n",
            "Validation loss: 0.2041, accuracy: 0.9365\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1561 - accuracy: 0.9509 - val_loss: 0.0781 - val_accuracy: 0.9773\n",
            "Train loss: 0.0765, accuracy: 0.9779\n",
            "Validation loss: 0.0781, accuracy: 0.9773\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1512 - accuracy: 0.9535 - val_loss: 0.0594 - val_accuracy: 0.9827\n",
            "Train loss: 0.0594, accuracy: 0.9829\n",
            "Validation loss: 0.0594, accuracy: 0.9827\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.3670 - accuracy: 0.8847 - val_loss: 0.2252 - val_accuracy: 0.9324\n",
            "Train loss: 0.2174, accuracy: 0.9334\n",
            "Validation loss: 0.2252, accuracy: 0.9324\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1661 - accuracy: 0.9485 - val_loss: 0.0607 - val_accuracy: 0.9816\n",
            "Train loss: 0.0652, accuracy: 0.9803\n",
            "Validation loss: 0.0607, accuracy: 0.9816\n",
            "1875/1875 [==============================] - 16s 6ms/step - loss: 0.5199 - accuracy: 0.8195 - val_loss: 0.2651 - val_accuracy: 0.9150\n",
            "Train loss: 0.2722, accuracy: 0.9103\n",
            "Validation loss: 0.2651, accuracy: 0.9150\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 2.2750 - accuracy: 0.1294 - val_loss: 2.2680 - val_accuracy: 0.1331\n",
            "Train loss: 2.2676, accuracy: 0.1334\n",
            "Validation loss: 2.2680, accuracy: 0.1331\n",
            "1875/1875 [==============================] - 14s 6ms/step - loss: 0.1485 - accuracy: 0.9539 - val_loss: 0.0643 - val_accuracy: 0.9798\n",
            "Train loss: 0.0614, accuracy: 0.9818\n",
            "Validation loss: 0.0643, accuracy: 0.9798\n",
            "1875/1875 [==============================] - 16s 6ms/step - loss: 0.2743 - accuracy: 0.9079 - val_loss: 0.0697 - val_accuracy: 0.9788\n",
            "Train loss: 0.0822, accuracy: 0.9758\n",
            "Validation loss: 0.0697, accuracy: 0.9788\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.2805 - accuracy: 0.9096 - val_loss: 0.1401 - val_accuracy: 0.9565\n",
            "Train loss: 0.1563, accuracy: 0.9536\n",
            "Validation loss: 0.1401, accuracy: 0.9565\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1456 - accuracy: 0.9550 - val_loss: 0.0705 - val_accuracy: 0.9798\n",
            "Train loss: 0.0585, accuracy: 0.9834\n",
            "Validation loss: 0.0705, accuracy: 0.9798\n",
            "1875/1875 [==============================] - 16s 6ms/step - loss: 0.1574 - accuracy: 0.9532 - val_loss: 0.0562 - val_accuracy: 0.9849\n",
            "Train loss: 0.0566, accuracy: 0.9851\n",
            "Validation loss: 0.0562, accuracy: 0.9849\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1648 - accuracy: 0.9528 - val_loss: 0.1146 - val_accuracy: 0.9681\n",
            "Train loss: 0.1039, accuracy: 0.9716\n",
            "Validation loss: 0.1146, accuracy: 0.9681\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1504 - accuracy: 0.9537 - val_loss: 0.0498 - val_accuracy: 0.9847\n",
            "Train loss: 0.0516, accuracy: 0.9851\n",
            "Validation loss: 0.0498, accuracy: 0.9847\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.3962 - accuracy: 0.8682 - val_loss: 0.1829 - val_accuracy: 0.9441\n",
            "Train loss: 0.1979, accuracy: 0.9400\n",
            "Validation loss: 0.1829, accuracy: 0.9441\n",
            "1875/1875 [==============================] - 14s 6ms/step - loss: 0.4110 - accuracy: 0.8617 - val_loss: 0.1733 - val_accuracy: 0.9488\n",
            "Train loss: 0.1726, accuracy: 0.9504\n",
            "Validation loss: 0.1733, accuracy: 0.9488\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1546 - accuracy: 0.9541 - val_loss: 0.0716 - val_accuracy: 0.9814\n",
            "Train loss: 0.0628, accuracy: 0.9840\n",
            "Validation loss: 0.0716, accuracy: 0.9814\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1512 - accuracy: 0.9557 - val_loss: 0.0731 - val_accuracy: 0.9810\n",
            "Train loss: 0.0707, accuracy: 0.9833\n",
            "Validation loss: 0.0731, accuracy: 0.9810\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.7452 - accuracy: 0.7369 - val_loss: 0.2706 - val_accuracy: 0.9151\n",
            "Train loss: 0.2832, accuracy: 0.9118\n",
            "Validation loss: 0.2706, accuracy: 0.9151\n",
            "1875/1875 [==============================] - 14s 6ms/step - loss: 0.1564 - accuracy: 0.9531 - val_loss: 0.0889 - val_accuracy: 0.9743\n",
            "Train loss: 0.0860, accuracy: 0.9752\n",
            "Validation loss: 0.0889, accuracy: 0.9743\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1562 - accuracy: 0.9539 - val_loss: 0.0512 - val_accuracy: 0.9844\n",
            "Train loss: 0.0519, accuracy: 0.9859\n",
            "Validation loss: 0.0512, accuracy: 0.9844\n",
            "1875/1875 [==============================] - 16s 7ms/step - loss: 0.1700 - accuracy: 0.9500 - val_loss: 0.0674 - val_accuracy: 0.9831\n",
            "Train loss: 0.0612, accuracy: 0.9829\n",
            "Validation loss: 0.0674, accuracy: 0.9831\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1474 - accuracy: 0.9566 - val_loss: 0.1133 - val_accuracy: 0.9735\n",
            "Train loss: 0.1034, accuracy: 0.9771\n",
            "Validation loss: 0.1133, accuracy: 0.9735\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.3473 - accuracy: 0.8779 - val_loss: 0.0946 - val_accuracy: 0.9730\n",
            "Train loss: 0.0971, accuracy: 0.9715\n",
            "Validation loss: 0.0946, accuracy: 0.9730\n",
            "1875/1875 [==============================] - 16s 6ms/step - loss: 0.3713 - accuracy: 0.8692 - val_loss: 0.1034 - val_accuracy: 0.9707\n",
            "Train loss: 0.0979, accuracy: 0.9736\n",
            "Validation loss: 0.1034, accuracy: 0.9707\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1594 - accuracy: 0.9522 - val_loss: 0.0742 - val_accuracy: 0.9773\n",
            "Train loss: 0.0661, accuracy: 0.9812\n",
            "Validation loss: 0.0742, accuracy: 0.9773\n",
            "1875/1875 [==============================] - 15s 7ms/step - loss: 0.1603 - accuracy: 0.9523 - val_loss: 0.0604 - val_accuracy: 0.9823\n",
            "Train loss: 0.0482, accuracy: 0.9863\n",
            "Validation loss: 0.0604, accuracy: 0.9823\n",
            "1875/1875 [==============================] - 14s 6ms/step - loss: 0.2681 - accuracy: 0.9135 - val_loss: 0.1031 - val_accuracy: 0.9700\n",
            "Train loss: 0.1056, accuracy: 0.9703\n",
            "Validation loss: 0.1031, accuracy: 0.9700\n",
            "1875/1875 [==============================] - 14s 6ms/step - loss: 0.1568 - accuracy: 0.9528 - val_loss: 0.0675 - val_accuracy: 0.9810\n",
            "Train loss: 0.0628, accuracy: 0.9822\n",
            "Validation loss: 0.0675, accuracy: 0.9810\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1633 - accuracy: 0.9516 - val_loss: 0.0630 - val_accuracy: 0.9836\n",
            "Train loss: 0.0592, accuracy: 0.9850\n",
            "Validation loss: 0.0630, accuracy: 0.9836\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1503 - accuracy: 0.9541 - val_loss: 0.0597 - val_accuracy: 0.9828\n",
            "Train loss: 0.0552, accuracy: 0.9835\n",
            "Validation loss: 0.0597, accuracy: 0.9828\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1586 - accuracy: 0.9531 - val_loss: 0.0893 - val_accuracy: 0.9764\n",
            "Train loss: 0.0780, accuracy: 0.9792\n",
            "Validation loss: 0.0893, accuracy: 0.9764\n",
            "1875/1875 [==============================] - 16s 7ms/step - loss: 0.1698 - accuracy: 0.9498 - val_loss: 0.0584 - val_accuracy: 0.9830\n",
            "Train loss: 0.0573, accuracy: 0.9847\n",
            "Validation loss: 0.0584, accuracy: 0.9830\n",
            "1875/1875 [==============================] - 16s 6ms/step - loss: 0.1663 - accuracy: 0.9503 - val_loss: 0.0626 - val_accuracy: 0.9832\n",
            "Train loss: 0.0657, accuracy: 0.9818\n",
            "Validation loss: 0.0626, accuracy: 0.9832\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1646 - accuracy: 0.9511 - val_loss: 0.0656 - val_accuracy: 0.9810\n",
            "Train loss: 0.0646, accuracy: 0.9819\n",
            "Validation loss: 0.0656, accuracy: 0.9810\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.6144 - accuracy: 0.7828 - val_loss: 0.2550 - val_accuracy: 0.9213\n",
            "Train loss: 0.2617, accuracy: 0.9194\n",
            "Validation loss: 0.2550, accuracy: 0.9213\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 2.2772 - accuracy: 0.1267 - val_loss: 2.2717 - val_accuracy: 0.1306\n",
            "Train loss: 2.2720, accuracy: 0.1312\n",
            "Validation loss: 2.2717, accuracy: 0.1306\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1606 - accuracy: 0.9509 - val_loss: 0.0799 - val_accuracy: 0.9791\n",
            "Train loss: 0.0745, accuracy: 0.9813\n",
            "Validation loss: 0.0799, accuracy: 0.9791\n",
            "1875/1875 [==============================] - 16s 7ms/step - loss: 0.1645 - accuracy: 0.9517 - val_loss: 0.0830 - val_accuracy: 0.9772\n",
            "Train loss: 0.0791, accuracy: 0.9790\n",
            "Validation loss: 0.0830, accuracy: 0.9772\n",
            "1875/1875 [==============================] - 16s 7ms/step - loss: 0.1527 - accuracy: 0.9562 - val_loss: 0.0449 - val_accuracy: 0.9873\n",
            "Train loss: 0.0457, accuracy: 0.9879\n",
            "Validation loss: 0.0449, accuracy: 0.9873\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1612 - accuracy: 0.9512 - val_loss: 0.1973 - val_accuracy: 0.9599\n",
            "Train loss: 0.1840, accuracy: 0.9629\n",
            "Validation loss: 0.1973, accuracy: 0.9599\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.3757 - accuracy: 0.8706 - val_loss: 0.1062 - val_accuracy: 0.9730\n",
            "Train loss: 0.1035, accuracy: 0.9740\n",
            "Validation loss: 0.1062, accuracy: 0.9730\n",
            "1875/1875 [==============================] - 16s 6ms/step - loss: 0.3111 - accuracy: 0.8912 - val_loss: 0.0721 - val_accuracy: 0.9805\n",
            "Train loss: 0.0728, accuracy: 0.9799\n",
            "Validation loss: 0.0721, accuracy: 0.9805\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.1583 - accuracy: 0.9526 - val_loss: 0.1103 - val_accuracy: 0.9692\n",
            "Train loss: 0.1127, accuracy: 0.9697\n",
            "Validation loss: 0.1103, accuracy: 0.9692\n",
            "1875/1875 [==============================] - 17s 7ms/step - loss: 0.3387 - accuracy: 0.8800 - val_loss: 0.0938 - val_accuracy: 0.9747\n",
            "Train loss: 0.1018, accuracy: 0.9741\n",
            "Validation loss: 0.0938, accuracy: 0.9747\n",
            "1875/1875 [==============================] - 15s 6ms/step - loss: 0.3045 - accuracy: 0.9048 - val_loss: 0.1547 - val_accuracy: 0.9568\n",
            "Train loss: 0.1549, accuracy: 0.9537\n",
            "Validation loss: 0.1547, accuracy: 0.9568\n",
            "1875/1875 [==============================] - 16s 6ms/step - loss: 0.3318 - accuracy: 0.8839 - val_loss: 0.0876 - val_accuracy: 0.9753\n",
            "Train loss: 0.0982, accuracy: 0.9734\n",
            "Validation loss: 0.0876, accuracy: 0.9753\n",
            "1875/1875 [==============================] - 16s 6ms/step - loss: 0.3068 - accuracy: 0.9010 - val_loss: 0.1023 - val_accuracy: 0.9774\n",
            "Train loss: 0.1091, accuracy: 0.9750\n",
            "Validation loss: 0.1023, accuracy: 0.9774\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.4111 - accuracy: 0.8616"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3a5dd3bc39c1>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Run optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-6b20dc49ccfb>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mlevel1_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel2_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel1_pso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimal level 1 parameters:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel1_opt\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [nC, nP, nF]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimal level 2 parameters:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel2_opt\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [c_nf, c_cs, c_pp, c_ss, p_fs, p_ss, p_pp, op]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-6b20dc49ccfb>\u001b[0m in \u001b[0;36mlevel1_pso\u001b[0;34m(self, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mparticles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_space_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_space_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_particles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_space_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mpbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparticles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mgbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparticles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel2_pso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_space_2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparticles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mvel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-6b20dc49ccfb>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mparticles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_space_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_space_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_particles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_space_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mpbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparticles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mgbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparticles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel2_pso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_space_2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparticles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mvel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-6b20dc49ccfb>\u001b[0m in \u001b[0;36mlevel2_pso\u001b[0;34m(self, Pi, X_train, y_train, X_val, y_val, search_space)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mnew_fitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_fitness\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m                     \u001b[0mpbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_fitness\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgbest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-6b20dc49ccfb>\u001b[0m in \u001b[0;36mcnn\u001b[0;34m(self, Pi, Pij, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m       \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1727\u001b[0m                             \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         )\n\u001b[0;32m-> 1729\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1730\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2070\u001b[0m                         ):\n\u001b[1;32m   2071\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}